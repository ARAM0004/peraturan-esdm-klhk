name: Auto-Scraper JDIH

on:
  schedule:
    - cron: '0 1 * * *'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        pip install requests beautifulsoup4 lxml
    
    - name: Run scraper
      run: |
        python .scripts/scraper.py
    
    - name: Pull latest changes
      run: |
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        git pull --rebase origin main
    
    - name: Commit and push if changed
      run: |
        git add regulations.json
        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          git commit -m "Auto-update regulations $(date +'%Y-%m-%d %H:%M:%S')"
          git push origin main
        fi
